# %%
import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Tuple
import matplotlib.pyplot as plt
import matplotlib as mpl
mpl.use("Agg")
mpl.rcParams['font.family'] = 'Malgun Gothic'
mpl.rcParams['axes.unicode_minus'] = False
pd.set_option("display.max_columns", None)
pd.set_option("display.width", 200)

OUTPUT_DIR = Path("./output_chi_test")
OUTPUT_DIR.mkdir(exist_ok=True, parents=True)

# ë¶„ì„ ë°ì´í„°ì…‹ ì»¬ëŸ¼ ì •ì˜
COL_TIME = ['ì‚¬ìš©ë…„ì›”', 'ì „ì²´ì¼ìˆ˜', 'ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜']
COL_WEATHER = ['ìµœê³ ê¸°ì˜¨', 'ìµœì €ê¸°ì˜¨', 'ê°•ìš°', 'í’ì†', 'ê°•ì„¤', 'ì•ˆê°œ', 'ë¯¸ì„¸ë¨¼ì§€']

def load_and_prepare(path_csv: str = "data.csv") -> pd.DataFrame:
    """ CSV ë¡œë“œ í›„ ë…„, ì›” íŒŒìƒë³€ìˆ˜ ì»¬ëŸ¼ì„ ìƒì„±. í•„ìš”ì—†ëŠ” ì»¬ëŸ¼ ì‚­ì œ í›„ data2.csv ì €ì¥ """
    # csv íŒŒì¼ ë¡œë“œ
    df = pd.read_csv(path_csv, sep='\t')    # csv íŒŒì¼ì€ tab ìœ¼ë¡œ êµ¬ë¶„ë˜ì–´ ìˆìŒ

    # ì „ì—­ë³€ìˆ˜ì— ì •ì˜ëœ ë°ì´í„°ì…‹ì˜ ì»¬ëŸ¼ë§Œ ì‚¬ìš©í•¨
    df = df[COL_TIME + COL_WEATHER]

    # datetime í˜•ì‹ ë³€í™˜, year & month ìƒì„±
    df['datetime'] = pd.to_datetime(df['ì‚¬ìš©ë…„ì›”'], errors='raise', format="%Yë…„%mì›”")  # '2025ë…„03ì›”' ë¬¸ìì—´ì„format ì„ ì§€ì •í•˜ì—¬ ì½ìŒ
    df['year'] = df['datetime'].dt.year
    df['month'] = df['datetime'].dt.month

    # ë¶„ì„ì— í•„ìš”ì—†ëŠ” ë°ì´í„° ì»¬ëŸ¼ ì‚­ì œ
    df.drop(columns=['ì‚¬ìš©ë…„ì›”', 'datetime'], inplace=True, errors='raise')

    return df

def create_weather_score(df: pd.DataFrame) -> Tuple[pd.DataFrame, np.ndarray]:
    data = df.copy()
    weather_features = [c for c in COL_WEATHER if c in data.columns]
    weather_data = data[weather_features].fillna(0).to_numpy(dtype=float)

    # ---- weightsëŠ” ì‚¬ìš©ìê°€ ìˆ˜ì •í•´ì•¼í•¨ ----
    weights = [0.15, 0.1, 0.3, 0.2, 0.05, 0.15, 0.05] # 2025-09-19 ì„¤ì • ì €ì¥

    # weather ë°ì´í„° ì»¬ëŸ¼ë“¤ê³¼ ê°€ì¤‘ì¹˜ì˜ ê³±
    risk_score = weather_data.dot(weights)

    percentiles = np.percentile(risk_score, [20, 40, 60, 80])

    def assign(score: float) -> int:
        if score <= percentiles[0]:
            return 5
        elif score <= percentiles[1]:
            return 4
        elif score <= percentiles[2]:
            return 3
        elif score <= percentiles[3]:
            return 2
        else:
            return 1

    # weather_score ì»¬ëŸ¼ì— ë‚ ì”¨ì ìˆ˜ ì €ì¥
    data['weather_score'] = [assign(s) for s in risk_score]

    # percentiles ëŠ” ì €ì¥í•´ë‘ê³  ìƒˆë¡œìš´ ë°ì´í„° ë“¤ì–´ì˜¬ë•Œ ì‚¬ìš©í•´ì•¼ í•œë‹¤.
    return data, percentiles

# %%

# data load, ë³€í™˜, íŒŒìƒë³€ìˆ˜ì»¬ëŸ¼ ìƒì„±
df = load_and_prepare('data.csv')

# íŒŒìƒë³€ìˆ˜ ì»¬ëŸ¼ ì¶”ê°€ ìƒì„±
df, weather_percentiles = create_weather_score(df)

# ì»¬ëŸ¼ëª… ìˆœì„œ ì¬ì§€ì •
column_name_order = ['year', 'month', 'ì „ì²´ì¼ìˆ˜', 'ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜', 'weather_score', 'ìµœê³ ê¸°ì˜¨', 'ìµœì €ê¸°ì˜¨', 'ê°•ìš°', 'í’ì†', 'ê°•ì„¤', 'ì•ˆê°œ', 'ë¯¸ì„¸ë¨¼ì§€']
df = df[column_name_order]

# íŒŒìƒë³€ìˆ˜ë¥¼ í¬í•¨í•œ ë°ì´í„°ì…‹ ì €ì¥
df.to_csv(OUTPUT_DIR / 'data2.csv', index=False)

# %%
from typing import Literal
from dataclasses import dataclass
import warnings
import scipy.stats as st
import statsmodels.api as sm
import statsmodels.formula.api as smf

@dataclass
class TestOutputs:
    glm_summary_path: str
    calibration_png: str
    trend_json: str
    chi_json: str
    corr_json: str

def _working_rate_bins(x: pd.Series, k: int = 5) -> pd.Series:
    """ì‘ì—…ê°€ëŠ¥ìœ¨ì„ kë¶„ìœ„ ì´ì‚°í™”(ì¹´ì´ì œê³±ìš©)."""
    rate = x.clip(0, 1)
    r = pd.qcut(rate.rank(method="first"), q=k, labels=[f"Q{i}" for i in range(1, k+1)])
    return r

def fit_binomial_glm(
    df: pd.DataFrame,
    treat_score_as: Literal["ordinal","numeric"] = "ordinal"
) -> Tuple[object, pd.DataFrame, dict]:
    """
    GLM(Binomial): ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜ ~ Binomial(ì „ì²´ì¼ìˆ˜, p), logit(p) = Î²0 + f(weather_score)
    ë°˜í™˜: (ê²°ê³¼ê°ì²´, ìº˜ë¦¬ë¸Œë ˆì´ì…˜DF, ìš”ì•½ë”•íŠ¸)
    """
    data = df.copy()
    data = data.dropna(subset=["ì „ì²´ì¼ìˆ˜","ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜","weather_score"])
    data = data.loc[data["ì „ì²´ì¼ìˆ˜"] > 0].copy()
    data["rate"] = data["ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜"] / data["ì „ì²´ì¼ìˆ˜"]

    if treat_score_as == "ordinal":
        data["weather_score"] = data["weather_score"].astype("category")
        formula = "rate ~ C(weather_score)"
    else:
        formula = "rate ~ weather_score"

    model = smf.glm(formula=formula, data=data,
                    family=sm.families.Binomial(), freq_weights=data["ì „ì²´ì¼ìˆ˜"])
    res = model.fit()

    # ìº˜ë¦¬ë¸Œë ˆì´ì…˜: ê´€ì¸¡ìœ¨ vs ì˜ˆì¸¡ìœ¨(ê°€ì¤‘í‰ê· )
    data["pred"] = res.predict(data)
    calib = (
        data[["weather_score","ì „ì²´ì¼ìˆ˜","ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜","pred"]]
        .groupby("weather_score", observed=True)
        .apply(
            lambda g: pd.Series({
                "n_months": len(g),
                "total_days": g["ì „ì²´ì¼ìˆ˜"].sum(),
                "total_work": g["ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜"].sum(),
                "obs_rate": g["ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜"].sum() / g["ì „ì²´ì¼ìˆ˜"].sum(),
                "pred_rate_weighted": np.average(g["pred"], weights=g["ì „ì²´ì¼ìˆ˜"])
            }),
            include_groups=False
        )
        .reset_index()
    )

    # í”Œë¡¯ ì €ì¥
    fig = plt.figure(figsize=(5,4))
    xs = calib["weather_score"].astype(str)
    plt.plot(xs, calib["obs_rate"], marker="o", label="ê´€ì¸¡ìœ¨")
    plt.plot(xs, calib["pred_rate_weighted"], marker="s", label="ì˜ˆì¸¡ìœ¨")
    plt.xlabel("weather_score"); plt.ylabel("ì‘ì—…ê°€ëŠ¥ìœ¨"); plt.title("ìº˜ë¦¬ë¸Œë ˆì´ì…˜(ê´€ì¸¡ vs ì˜ˆì¸¡)")
    plt.legend(); fig.tight_layout()
    cal_path = str(OUTPUT_DIR / "calibration_weather_score.png")
    fig.savefig(cal_path, dpi=150); plt.close(fig)

    # ìš”ì•½ ì €ì¥ + LR test
    summ_path = str(OUTPUT_DIR / "glm_binomial_weather_score.txt")
    with open(summ_path, "w", encoding="utf-8") as f:
        f.write(res.summary().as_text())

    base = smf.glm("rate ~ 1", data=data,
                   family=sm.families.Binomial(),
                   freq_weights=data["ì „ì²´ì¼ìˆ˜"]).fit()
    lr_stat = float(2*(res.llf - base.llf))
    df_diff = int(res.df_model - base.df_model)
    lr_p = float(1 - st.chi2.cdf(lr_stat, df_diff))
    with open(summ_path, "a", encoding="utf-8") as f:
        f.write("\n\n[Likelihood Ratio Test vs Intercept-only]\n")
        f.write(f"LR stat={lr_stat:.3f}, df={df_diff}, p-value={lr_p:.6f}\n")
        f.write(f"AIC(full)={res.aic:.3f}, AIC(base)={base.aic:.3f}\n")

    info = {
        "formula": formula,
        "aic_full": float(res.aic),
        "aic_base": float(base.aic),
        "lr_stat": lr_stat,
        "lr_df": df_diff,
        "lr_p": lr_p,
        "n_obs": int(len(data)),
    }

    # ë³´ì¡° ì €ì¥
    (OUTPUT_DIR / "calibration_by_score.csv").write_text(
        calib.to_csv(index=False, encoding="utf-8-sig"), encoding="utf-8"
    )

    return res, calib, info

def cochran_armitage_trend(df: pd.DataFrame) -> dict:
    """Cochranâ€“Armitage ì¶”ì„¸ê²€ì •(ì§ì ‘ êµ¬í˜„). ê²°ê³¼ JSON ì €ì¥."""
    g = df.groupby("weather_score", observed=True).agg(
        success=("ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜","sum"),
        trials=("ì „ì²´ì¼ìˆ˜","sum")
    ).sort_index()
    g["fail"] = g["trials"] - g["success"]

    k = g.shape[0]
    scores = np.arange(1, k+1, dtype=float)
    n = float(g["trials"].sum())
    p_hat = float(g["success"].sum() / n)

    num = float(np.sum(scores * (g["success"] - g["trials"]*p_hat)))
    denom = float(np.sqrt(p_hat*(1-p_hat) * (np.sum(g["trials"]*scores**2) - (np.sum(g["trials"]*scores)**2)/n)))
    z_stat = num / denom if denom > 0 else np.nan
    p_val = float(2 * (1 - st.norm.cdf(abs(z_stat))))

    out = {"statistic": z_stat, "p_value": p_val, "method": "Cochran-Armitage trend test (manual)", "k": int(k)}
    (OUTPUT_DIR / "trend_test.json").write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
    return out

def chi_square_independence(df: pd.DataFrame, k_bins: int = 5) -> dict:
    """ì¹´ì´ì œê³± ë…ë¦½ì„± + CramÃ©râ€™s V. ê²°ê³¼ JSON ì €ì¥."""
    tmp = df.copy()
    tmp["rate"] = tmp["ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜"] / tmp["ì „ì²´ì¼ìˆ˜"]
    tmp = tmp.dropna(subset=["rate","weather_score"])
    tmp = tmp.loc[tmp["ì „ì²´ì¼ìˆ˜"] > 0]
    tmp["rate_bin"] = _working_rate_bins(tmp["rate"], k=k_bins)

    ct = pd.crosstab(tmp["weather_score"], tmp["rate_bin"])
    chi2, p, dof, _ = st.chi2_contingency(ct.values)

    n = ct.values.sum()
    r, c = ct.shape
    cramers_v = float(np.sqrt((chi2/n) / (min(r-1, c-1))))

    out = {"chi2": float(chi2), "p_value": float(p), "dof": int(dof),
           "cramers_v": cramers_v, "n": int(n), "k_bins": int(k_bins)}
    (OUTPUT_DIR / "chi_square_independence.json").write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
    return out

def monotone_correlations(df: pd.DataFrame) -> dict:
    """Spearman, Kendall tau-b. ê²°ê³¼ JSON ì €ì¥."""
    x = df["weather_score"].astype(float)
    y = (df["ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜"] / df["ì „ì²´ì¼ìˆ˜"]).astype(float)
    mask = x.notna() & y.notna() & (df["ì „ì²´ì¼ìˆ˜"] > 0)
    x, y = x[mask], y[mask]

    spear = st.spearmanr(x, y)
    kend = st.kendalltau(x, y, variant="b")
    out = {
        "spearman_rho": float(spear.correlation),
        "spearman_p": float(spear.pvalue),
        "kendall_tau_b": float(kend.statistic),
        "kendall_p": float(kend.pvalue)
    }
    (OUTPUT_DIR / "ordinal_correlations.json").write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")
    return out

def _print_console_summary(glm_info: dict, trend: dict, chi: dict, corr: dict, res_obj) -> None:
    """ì½˜ì†” ìš”ì•½ ì¶œë ¥."""
    print("\n=== [ìš”ì•½] weather_score ì í•©ì„± ê²€ì • ===")
    # GLM
    print("[GLM Binomial]")
    print(f"  formula     : {glm_info['formula']}")
    print(f"  n_obs       : {glm_info['n_obs']}")
    print(f"  AIC full    : {glm_info['aic_full']:.3f}   | AIC base: {glm_info['aic_base']:.3f}")
    print(f"  LR test     : stat={glm_info['lr_stat']:.3f}, df={glm_info['lr_df']}, p={glm_info['lr_p']:.3g}")
    # ì£¼ìš” ê³„ìˆ˜ ìš”ì•½(ìƒìœ„ ëª‡ ê°œë§Œ)
    try:
        coefs = res_obj.summary2().tables[1]
        top = min(6, len(coefs))
        print("  Coeff head  :")
        for i in range(top):
            row = coefs.iloc[i]
            print(f"    {coefs.index[i]:<18} coef={row['Coef.']:.4f}  z={row['z']:.2f}  p={row['P>|z|']:.3g}")
    except Exception:
        pass

    # ì¶”ì„¸ê²€ì •
    print("[Cochran-Armitage trend]")
    print(f"  Z={trend['statistic']:.3f}, p={trend['p_value']:.3g}, k={trend['k']}")

    # ì¹´ì´ì œê³±
    print("[Chi-square independence]")
    print(f"  chi2={chi['chi2']:.3f}, df={chi['dof']}, p={chi['p_value']:.3g}, CramÃ©r's V={chi['cramers_v']:.3f}, n={chi['n']}")

    # ìˆœì„œìƒê´€
    print("[Ordinal correlations]")
    print(f"  Spearman rho={corr['spearman_rho']:.3f}, p={corr['spearman_p']:.3g}")
    print(f"  Kendall tau-b={corr['kendall_tau_b']:.3f}, p={corr['kendall_p']:.3g}")
    print("=== ë ===\n")

def run_all_tests(df: pd.DataFrame) -> TestOutputs:
    """
    1) GLM + LR test + ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼/ê·¸ë¦¼ ì €ì¥
    2) Cochranâ€“Armitage ì¶”ì„¸ê²€ì • JSON ì €ì¥
    3) ì¹´ì´ì œê³± ë…ë¦½ì„± + CramÃ©râ€™s V JSON ì €ì¥
    4) Spearman/Kendall JSON ì €ì¥
    5) ì½˜ì†” ìš”ì•½ ì¶œë ¥
    """
    warnings.filterwarnings("ignore", category=RuntimeWarning)

    res, calib, glm_info = fit_binomial_glm(df, treat_score_as="ordinal")
    trend = cochran_armitage_trend(df)
    chi = chi_square_independence(df, k_bins=5)
    corr = monotone_correlations(df)

    # ì½˜ì†” ê²½ë¡œ ì•ˆë‚´ + ìš”ì•½
    print("[OK] Binomial GLM summary :", str(OUTPUT_DIR / "glm_binomial_weather_score.txt"))
    print("[OK] Calibration plot     :", str(OUTPUT_DIR / "calibration_weather_score.png"))
    print("[OK] Trend test JSON      :", str(OUTPUT_DIR / "trend_test.json"))
    print("[OK] Chi-square JSON      :", str(OUTPUT_DIR / "chi_square_independence.json"))
    print("[OK] Ordinal corr JSON    :", str(OUTPUT_DIR / "ordinal_correlations.json"))
    # í•µì‹¬ ìš”ì•½
    _print_console_summary(glm_info, trend, chi, corr, res)

    return TestOutputs(
        glm_summary_path=str(OUTPUT_DIR / "glm_binomial_weather_score.txt"),
        calibration_png=str(OUTPUT_DIR / "calibration_weather_score.png"),
        trend_json=str(OUTPUT_DIR / "trend_test.json"),
        chi_json=str(OUTPUT_DIR / "chi_square_independence.json"),
        corr_json=str(OUTPUT_DIR / "ordinal_correlations.json"),
    )

# === ì‹¤í–‰ ===
tests_out = run_all_tests(df)
# %%
'''
[OK] Binomial GLM summary : output_chi_test\glm_binomial_weather_score.txt
[OK] Calibration plot     : output_chi_test\calibration_weather_score.png
[OK] Trend test JSON      : output_chi_test\trend_test.json
[OK] Chi-square JSON      : output_chi_test\chi_square_independence.json
[OK] Ordinal corr JSON    : output_chi_test\ordinal_correlations.json

=== [ìš”ì•½] weather_score ì í•©ì„± ê²€ì • ===
[GLM Binomial]
  formula     : rate ~ C(weather_score)
  n_obs       : 180
  AIC full    : 4744.116   | AIC base: 5040.281
  LR test     : stat=304.165, df=4, p=0
  Coeff head  :
    Intercept          coef=-0.4214  z=-6.66  p=2.68e-11
    C(weather_score)[T.2] coef=0.6050  z=6.99  p=2.67e-12
    C(weather_score)[T.3] coef=0.9066  z=10.07  p=7.32e-24
    C(weather_score)[T.4] coef=1.0853  z=12.15  p=5.6e-34
    C(weather_score)[T.5] coef=1.4649  z=15.77  p=5.17e-56
[Cochran-Armitage trend]
  Z=16.932, p=0, k=5
[Chi-square independence]
  chi2=185.282, df=16, p=7.34e-31, CramÃ©r's V=0.507, n=180
[Ordinal correlations]
  Spearman rho=0.848, p=5.6e-51
  Kendall tau-b=0.717, p=4.91e-38
=== ë ===

1. GLM Binomial ê²°ê³¼

ê³µì‹: rate ~ C(weather_score)

ìƒ˜í”Œ ìˆ˜: 180ê°œì›”

AIC ê°ì†Œ: baseëª¨í˜•(5040.3) â†’ fullëª¨í˜•(4744.1). AICê°€ í¬ê²Œ ë‚®ì•„ì ¸ weather_scoreê°€ ì„¤ëª…ë ¥ì„ ìƒë‹¹íˆ ë†’ì„.

LR ê²€ì •: Ï‡Â²=304.2, df=4, pâ‰ˆ0.0 â†’ ê·€ë¬´ê°€ì„¤(ì„¤ëª…ë ¥ ì—†ìŒ) ê¸°ê°.

ê³„ìˆ˜: score=2~5ì—ì„œ ê³„ìˆ˜ê°€ ëª¨ë‘ ì–‘ìˆ˜ì´ë©°, p<1e-11 ìˆ˜ì¤€ìœ¼ë¡œ ìœ ì˜. ì¦‰ weather_scoreê°€ ë†’ì„ìˆ˜ë¡ ì‘ì—…ê°€ëŠ¥ìœ¨ì´ ìœ ì˜í•˜ê²Œ ì¦ê°€.

2. Cochran-Armitage ì¶”ì„¸ê²€ì •

Z=16.9, pâ‰ˆ0 â†’ 1~5 ìˆœì„œëŒ€ë¡œ ì‘ì—…ê°€ëŠ¥ìœ¨ì´ ë‹¨ì¡°ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê°•í•œ ì¶”ì„¸ ì¡´ì¬.

3. ì¹´ì´ì œê³± ë…ë¦½ì„± ê²€ì •

Ï‡Â²=185.3, df=16, pâ‰ˆ7e-31 â†’ ë…ë¦½ ì•„ë‹˜. weather_scoreì™€ ì‘ì—…ê°€ëŠ¥ìœ¨ ë¶„ìœ„ ê·¸ë£¹ ê°„ì— ëšœë ·í•œ ì—°ê´€ì„±.

CramÃ©râ€™s V=0.507 â†’ íš¨ê³¼í¬ê¸° ê¸°ì¤€(0.1=ì†Œ, 0.3=ì¤‘, 0.5=ëŒ€)ì—ì„œ í° íš¨ê³¼.

4. ìˆœì„œìƒê´€

Spearman rho=0.848, Kendall tau-b=0.717 â†’ ë§¤ìš° ê°•í•œ ì–‘ì˜ ìƒê´€. pê°’ì€ ê·¹ì†Œ.

ì¢…í•© ê²°ë¡ 

ë„¤ ê°€ì§€ ì ‘ê·¼(GLM, ì¶”ì„¸ê²€ì •, ì¹´ì´ì œê³±, ìƒê´€ë¶„ì„) ëª¨ë‘ ì¼ê´€ë˜ê²Œ ê°•í•œ ì–‘ì˜ ê´€ê³„ë¥¼ í™•ì¸.

weather_scoreëŠ” ë‹¨ìˆœíˆ ì´ë¡ ì  ì§€í‘œê°€ ì•„ë‹ˆë¼ ì‹¤ì œ ì‘ì—…ê°€ëŠ¥ì¼ìˆ˜ ì˜ˆì¸¡ ë³€ìˆ˜ë¡œ ë§¤ìš° ì˜ ì‘ë™í•¨.

íŠ¹íˆ GLM ê³„ìˆ˜ì™€ AIC ê°œì„ í­, CramÃ©râ€™s V 0.5 ì´ìƒì˜ í° íš¨ê³¼í¬ê¸°ê°€ ì´ë¥¼ ë’·ë°›ì¹¨.

ì¦‰, í˜„ì¬ ì •ì˜ëœ ë°©ì‹ì˜ weather_scoreëŠ” í†µê³„ì ìœ¼ë¡œë„ ì í•©í•˜ê³ , ì˜ˆì¸¡ëª¨í˜•ì— ê°•ë ¥í•˜ê²Œ ê¸°ì—¬í•˜ëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤.

ğŸ‘‰ ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•˜í–¥ì‹ ëª¨ë¸ë§(ì˜ˆ: ì‘ì—…ê°€ëŠ¥ìœ¨ ~ weather_score + ê¸°íƒ€ ê¸°ìƒë³€ìˆ˜)ë¡œ í™•ì¥í•˜ë©´, ë‹¤ë¥¸ ê¸°ìƒ ë³€ìˆ˜ ëŒ€ë¹„ weather_scoreì˜ ì¢…í•©ì  ëŒ€í‘œì„±ë„ ê²€ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

'''